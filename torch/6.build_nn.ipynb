{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd84a02",
   "metadata": {},
   "source": [
    "# Build the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb954c",
   "metadata": {},
   "source": [
    "**ネスト構造**  \n",
    "小さなモジュールを組み合わせて大きなモジュールを作成する。  \n",
    "ニューラルネットワーク自体がモジュール（部品、関数やクラスのように小分けにして再利用しやすいようにしている）であり、以下のような階層に分かれている。  \n",
    "- レイヤー（最小単位）  \n",
    "nn.Moduleの一種である、nn.Linear（全結合層）や nn.Conv2d（畳み込み層）など。\n",
    "- ブロック（中間単位）  \n",
    "複数のレイヤーをまとめたもの  \n",
    "\n",
    "小さなモジュールを組み合わせて、大きなモジュールを作成する。  \n",
    "　例）  \n",
    "```nn.Linear```　　全結合層  \n",
    "```nn.ReLU```　　　活性化関数  \n",
    "```nn.Conv2d```　　畳み込み層  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e6f9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e43df7",
   "metadata": {},
   "source": [
    "## デバイスを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aede3a",
   "metadata": {},
   "source": [
    "利用できるアクセラレータ（処理を行うデバイス）を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96e13c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f6987",
   "metadata": {},
   "source": [
    "## クラスを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6aeb435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()              # nn.Moduleの機能を呼び出す\n",
    "        self.flatten = nn.Flatten()     # 二次元の画像を1次元の配列にならす。Linearは1次元しか受け取れないらしい\n",
    "                                        # 入力が28*28ならば、784ピクセルになる\n",
    "        self.linear_relu_stack = nn.Sequential(     # 複数のレイヤーを順番に実行するためのまとめた箱\n",
    "            nn.Linear(28*28, 512),      # 入力784を512個の特徴量に変換\n",
    "            nn.ReLU(),                  # 活性化関数\n",
    "            nn.Linear(512, 512),        # 512を受け取って、512を返す\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),         # 全結合層として、10ラベルに分類し予測する\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)             # データを1列に変えて、\n",
    "        logits = self.linear_relu_stack(x)          # レイヤーに通す。\n",
    "        return logits                               # ロジット"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce206d63",
   "metadata": {},
   "source": [
    "- ロジット  \n",
    "確率になる前の生の結果数値。  \n",
    "例えば、[10.2, -2.1, 0.5, ...] のように出力され、一番大きい数値のインデックスが「モデルの予想（答え）」になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5f0513b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78ab5a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class :tensor([7])\n",
      "torch.Size([1, 10])\n",
      "tensor([[ 0.0088, -0.0232, -0.0939,  0.0500, -0.0589, -0.0120, -0.1291,  0.0833,\n",
      "          0.0411, -0.0291]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "\n",
    "print(f\"Predicted class :{y_pred}\")\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53db41",
   "metadata": {},
   "source": [
    "予測ラベルのロジットを確認すると、確かに一番大きい値となっていることがわかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5f532",
   "metadata": {},
   "source": [
    "## 上記の中身を詳しく見ていこう"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9758c6",
   "metadata": {},
   "source": [
    "### モデルの各レイヤー"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f11979",
   "metadata": {},
   "source": [
    "サンプルミニバッチを準備し、ネットワークに通してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4d75f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())\n",
    "#input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bba85e",
   "metadata": {},
   "source": [
    "#### nn.Flatten  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e61bb",
   "metadata": {},
   "source": [
    "28*28の2d画像を784個の1次元配列に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50386e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "#flat_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab554bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flat_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97179b0e",
   "metadata": {},
   "source": [
    "上記をみてわかる通り、赤青緑それぞれを表す列があり、それらは784個の要素をもとに構成された。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd52558",
   "metadata": {},
   "source": [
    "#### nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0292ecc",
   "metadata": {},
   "source": [
    "保存された重みとバイアスを使用して入力を線形変換。  \n",
    "\n",
    "$$y = xA^T + b$$\n",
    "\n",
    "x: 入力したデータ  \n",
    "A: 重み（重要視するポイント（要素））  \n",
    "b: バイアス  \n",
    "y: 出力  \n",
    "\n",
    "入力データをもとに、重要な特徴部分を残して（まとめて？）20個の出力としている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183f87f",
   "metadata": {},
   "source": [
    "\n",
    "$$\\text{Output (20)} = \\text{Input (784)} \\times \\text{Weights (784, 20)} + \\text{Bias (20)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d70b72f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3039cd5d",
   "metadata": {},
   "source": [
    "layer1という入力（in_features）を合わせて、出力（out_features）を指定し、層を作成する。  \n",
    "前処理後(flat_image)を作成した層にいれることで、内部で線形化の計算が行われ、結果がhidden1に収納される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9688074f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49b71fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0124,  0.0262, -0.0194,  ...,  0.0211, -0.0175, -0.0225],\n",
       "        [ 0.0006, -0.0347,  0.0132,  ..., -0.0345,  0.0082, -0.0051],\n",
       "        [ 0.0221,  0.0275,  0.0219,  ...,  0.0032,  0.0087,  0.0160],\n",
       "        ...,\n",
       "        [ 0.0267, -0.0125, -0.0141,  ..., -0.0022,  0.0210,  0.0241],\n",
       "        [-0.0054, -0.0048, -0.0256,  ...,  0.0297, -0.0258,  0.0161],\n",
       "        [ 0.0046, -0.0270,  0.0301,  ..., -0.0252, -0.0292,  0.0233]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight#[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b949a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 784)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer1.weight), len(layer1.weight[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98922835",
   "metadata": {},
   "source": [
    "20個中1個の出力を得るための784要素分の重みが含まれているという事だろうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f5c91",
   "metadata": {},
   "source": [
    "#### nn.ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73518f",
   "metadata": {},
   "source": [
    "非線形活性化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d83ac546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.2835, -0.0899,  0.1448, -0.1582,  0.4209,  0.3880,  0.0963,  0.7778,\n",
      "          0.2744,  0.0863,  0.0157,  0.5735, -0.1913,  0.2347, -0.0427, -0.3022,\n",
      "         -0.1769, -0.0824, -0.1296, -0.0221],\n",
      "        [ 0.3179, -0.0629, -0.0704, -0.1931,  0.2399,  0.1597,  0.0652,  0.7289,\n",
      "         -0.0731,  0.2175,  0.0706,  0.4341, -0.3429,  0.0416,  0.1350, -0.6069,\n",
      "         -0.0045,  0.1441,  0.1868, -0.1669],\n",
      "        [ 0.5328,  0.1028, -0.0874, -0.4444,  0.2351,  0.1717,  0.2036,  0.7154,\n",
      "          0.2903,  0.2593,  0.1277,  0.2207, -0.0812, -0.0365, -0.0575, -0.4267,\n",
      "         -0.0049, -0.2597,  0.1094, -0.3920]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "After ReLU: tensor([[0.2835, 0.0000, 0.1448, 0.0000, 0.4209, 0.3880, 0.0963, 0.7778, 0.2744,\n",
      "         0.0863, 0.0157, 0.5735, 0.0000, 0.2347, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3179, 0.0000, 0.0000, 0.0000, 0.2399, 0.1597, 0.0652, 0.7289, 0.0000,\n",
      "         0.2175, 0.0706, 0.4341, 0.0000, 0.0416, 0.1350, 0.0000, 0.0000, 0.1441,\n",
      "         0.1868, 0.0000],\n",
      "        [0.5328, 0.1028, 0.0000, 0.0000, 0.2351, 0.1717, 0.2036, 0.7154, 0.2903,\n",
      "         0.2593, 0.1277, 0.2207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1094, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\")\n",
    "\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d71645",
   "metadata": {},
   "source": [
    "#### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fb452",
   "metadata": {},
   "source": [
    "上記のレイヤーをコンテナとしてまとめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "437ea02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "\n",
    "input_image = torch.rand(2, 28, 28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087957d5",
   "metadata": {},
   "source": [
    "#### nn.Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c258158",
   "metadata": {},
   "source": [
    "ロジットとして、各クラスの予測確立を表す。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e2dec6",
   "metadata": {},
   "source": [
    "**活性化関数**\n",
    "- ReLU:  \n",
    "中間層で使用される。0以下の数値は0に、それよりも大きい数値はそのまま返す。重要な情報のみを残し、あとは捨てる。\n",
    "- Softmax:  \n",
    "確率に変換。値の合計が1になる。\n",
    "$$\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e77f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "088c3cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0882, 0.0987, 0.1148, 0.1328, 0.0846, 0.1045, 0.0869, 0.0925, 0.0849,\n",
       "         0.1121],\n",
       "        [0.0820, 0.1082, 0.1031, 0.1398, 0.0828, 0.1000, 0.0885, 0.0838, 0.0888,\n",
       "         0.1230]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc6aa48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd211e",
   "metadata": {},
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91a170c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0247, -0.0233,  0.0085,  ...,  0.0079,  0.0107,  0.0352],\n",
      "        [-0.0340,  0.0017, -0.0352,  ...,  0.0195, -0.0280,  0.0081]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0163,  0.0023], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0101, -0.0400, -0.0046,  ..., -0.0194,  0.0198,  0.0331],\n",
      "        [ 0.0201,  0.0381,  0.0016,  ...,  0.0356,  0.0048,  0.0419]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0103,  0.0235], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0121,  0.0186, -0.0227,  ...,  0.0274,  0.0396, -0.0261],\n",
      "        [-0.0378, -0.0414,  0.0131,  ...,  0.0098,  0.0060,  0.0011]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0253, -0.0320], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
